name: external-server

resources:
  accelerators: A6000:2
  cloud: lambda

envs:
  MODEL: Qwen/Qwen2.5-Coder-32B-Instruct
  VERSION: b47205940b83b5b484577359f71ee7b88472df67
  # region where the main K3s server is hosted to retrieve cluster connection details
  AWS_DEFAULT_REGION: us-east-1

file_mounts:
  /r2:
    source: r2://lmrun
  ~/.aws/credentials: ~/.aws/ext-vm-credentials

setup: |
  set -e
  install -m 755 /r2/setup/k3s_* .
  sudo -E ./k3s_agent.py --app-port 8000 --node-port 30300

  python3 -m venv .venv
  . .venv/bin/activate
  pip install vllm hf-transfer

# max-model-len & gpu-memory optimized for wide 32B model compatibility on 96GB
run: |
  . .venv/bin/activate
  vllm serve -tp 2 --generation-config auto \
      --max-model-len 31120 --gpu-memory-utilization 0.94 \
      --served-model-name qwen-coder --revision $VERSION $MODEL